{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec: How To Prep Document Vectors For Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15317/1783091154.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Read in data, clean it, split it into train/test, and then train a doc2vec model\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('data/spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'],\n",
    "                                                    messages['label'], test_size=0.2)\n",
    "\n",
    "tagged_docs_tr = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_train)]\n",
    "\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs_tr,\n",
    "                                  vector_size=50,\n",
    "                                  window=2,\n",
    "                                  min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4058209e-03,  9.2724431e-03,  1.0380875e-02,  1.1536386e-02,\n",
       "       -9.6133966e-03, -2.6534690e-02,  3.4285650e-02,  4.5177564e-02,\n",
       "       -4.2598575e-02, -2.5352186e-02, -4.8029027e-03, -3.3557270e-02,\n",
       "        2.1707986e-02,  6.1855963e-03, -2.0106051e-02,  2.1855265e-02,\n",
       "        1.8184656e-02,  4.8137284e-03, -3.0561285e-02, -2.1981107e-02,\n",
       "        3.5878918e-03,  3.6914751e-02,  5.0335940e-02, -4.4280761e-03,\n",
       "        3.4850221e-02,  1.6598672e-02, -2.5551116e-02, -3.5004984e-04,\n",
       "       -4.0058989e-02, -2.0246326e-03,  5.7574306e-03,  1.5758423e-02,\n",
       "       -4.7831316e-03,  8.4976824e-03,  1.0870632e-03,  2.7282942e-02,\n",
       "        2.8971998e-02,  8.8960478e-05,  6.4460407e-03, -7.1150181e-03,\n",
       "        3.6508817e-02, -2.0062435e-02, -2.1368699e-02, -8.5655143e-03,\n",
       "        6.7441724e-02, -1.1323771e-03,  4.9993454e-04, -2.7205015e-02,\n",
       "        1.5395824e-02,  1.6925072e-02], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does a document vector look like again?\n",
    "d2v_model.infer_vector(['convert', 'words', 'to', 'vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we prepare these vectors to be used in a machine learning model?\n",
    "vectors = [[d2v_model.infer_vector(words)] for words in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.01966103, -0.05595076,  0.00282994, -0.00233608,  0.06975448,\n",
       "        -0.03656393,  0.0213115 ,  0.02819064, -0.08934025, -0.02582703,\n",
       "        -0.020344  , -0.04680223, -0.07381724, -0.00585467, -0.0060955 ,\n",
       "        -0.04879982,  0.04401538, -0.01002595,  0.00766305, -0.06041573,\n",
       "        -0.00166076,  0.00586077, -0.07065456, -0.01389735, -0.04266352,\n",
       "         0.01487691,  0.00241179, -0.01855587, -0.01449505, -0.00476608,\n",
       "        -0.05354033,  0.06879082, -0.00255322,  0.0489867 , -0.09231926,\n",
       "        -0.00930831, -0.03519291, -0.02682027,  0.00948574, -0.04765084,\n",
       "        -0.11541642, -0.0277185 ,  0.0118827 , -0.02079365,  0.04950323,\n",
       "         0.02471211, -0.01525378,  0.03903551, -0.0882815 ,  0.02118529],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
